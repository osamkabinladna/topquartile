{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8c7d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts wandb.exe and wb.exe are installed in 'C:\\Users\\LO79RS\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/36/d5/215cac3edec5c5ac6e7231beb9d22466d5d4e4a132fa3a1d044f7d682c15/wandb-0.19.11-py3-none-win_amd64.whl.metadata\n",
      "  Downloading wandb-0.19.11-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for gitpython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/1d/9a/4114a9057db2f1462d5c8f8390ab7383925fe1ac012eaa42402ad65c2963/GitPython-3.1.44-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\lo79rs\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (6.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (1.10.8)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=2.0.0 from https://files.pythonhosted.org/packages/f0/e5/da07b0bd832cefd52d16f2b9bbbe31624d57552602c06631686b93ccb1bd/sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/c9/15/52cf5e1ff0727d53704cfdde2858eaf237ce523b0b04db65faa84ff83e13/setproctitle-1.3.6-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading setproctitle-1.3.6-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/a0/61/5c78b91c3143ed5c14207f463aecfc8f9dbb5092fb2869baf37c273b2705/gitdb-4.0.12-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lo79rs\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/04/be/d09147ad1ec7934636ad912901c5fd7667e1c858e19d355237db0d0cd5e4/smmap-5.0.2-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.19.11-py3-none-win_amd64.whl (20.8 MB)\n",
      "   ---------------------------------------- 0.0/20.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/20.8 MB 3.4 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.2/20.8 MB 3.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/20.8 MB 5.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.5/20.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.1/20.8 MB 15.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.8/20.8 MB 17.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 3.9/20.8 MB 13.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.9/20.8 MB 13.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 8.1/20.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 9.4/20.8 MB 23.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 11.2/20.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 11.6/20.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 13.0/20.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 15.5/20.8 MB 38.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 17.0/20.8 MB 34.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 18.6/20.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.5/20.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.8/20.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.8/20.8 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 207.6/207.6 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "   ---------------------------------------- 0.0/341.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 341.6/341.6 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.6-cp311-cp311-win_amd64.whl (12 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.29.1 setproctitle-1.3.6 smmap-5.0.2 wandb-0.19.11\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8eeccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting quantile-forest\n",
      "  Obtaining dependency information for quantile-forest from https://files.pythonhosted.org/packages/c2/e3/03f4cdb528045d8514abcfe99eee615fc90035139c8328831847084766c2/quantile_forest-1.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading quantile_forest-1.4.0-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from quantile-forest) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.4 in c:\\users\\lo79rs\\appdata\\roaming\\python\\python311\\site-packages (from quantile-forest) (1.15.3)\n",
      "Collecting scikit-learn>=1.5 (from quantile-forest)\n",
      "  Obtaining dependency information for scikit-learn>=1.5 from https://files.pythonhosted.org/packages/a1/a6/c5b78606743a1f28eae8f11973de6613a5ee87366796583fb74c67d54939/scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.5->quantile-forest) (1.2.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.5->quantile-forest)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading quantile_forest-1.4.0-cp311-cp311-win_amd64.whl (279 kB)\n",
      "   ---------------------------------------- 0.0/279.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/279.6 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  276.5/279.6 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 279.6/279.6 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/11.1 MB 20.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/11.1 MB 19.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 24.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/11.1 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.3/11.1 MB 26.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 29.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.1/11.1 MB 30.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.1 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, quantile-forest\n",
      "Successfully installed quantile-forest-1.4.0 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install quantile-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7f0844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to PythonPath C:\\Users\\LO79RS\\topquartile\\topquartile\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path().resolve() / \"topquartile\"\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.insert(0, str(root))\n",
    "\n",
    "print(\"Added to PythonPath\", root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf00d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d739e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topquartile.modules.datamodule.partitions import PurgedTimeSeriesPartition\n",
    "from topquartile.modules.datamodule.dataloader import DataLoader\n",
    "from topquartile.modules.datamodule.transforms.covariate import TechnicalCovariateTransform\n",
    "from topquartile.modules.datamodule.transforms.label import BinaryLabelTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732af846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Dataloader with covariates_may2025v2\n",
    "covtrans_config = [(\n",
    "TechnicalCovariateTransform,\n",
    "dict(sma=[20, 30], ema=[20, 30], momentum_change=True, volatility=[20, 30]),\n",
    ")]\n",
    "\n",
    "labeltrans_config = [(BinaryLabelTransform, dict(label_duration=20, quantile=0.75))]\n",
    "\n",
    "partition_config = dict(n_splits=5, gap=20, max_train_size=504, test_size=60)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "data_id=\"covariates_may2025v2\",\n",
    "covariate_transform=covtrans_config,\n",
    "label_transform=labeltrans_config,\n",
    "partition_class=PurgedTimeSeriesPartition,\n",
    "partition_kwargs=partition_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba51d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not yet processed. Processing now...\n",
      "Reading data from: C:\\Users\\LO79RS\\topquartile\\topquartile\\data\\covariates_may2025v2.csv\n",
      "Found 134 raw ticker names.\n",
      " Applying TechnicalCovariateTransform with params {'sma': [20, 30], 'ema': [20, 30], 'momentum_change': True, 'volatility': [20, 30]}\n",
      "THIS IS COLUMNS Index(['TOTAL_EQUITY', 'BOOK_VAL_PER_SH', 'REVENUE_PER_SH', 'RETURN_COM_EQY',\n",
      "       'CUR_MKT_CAP', 'PX_LAST', 'TOT_DEBT_TO_TOT_ASSET',\n",
      "       'TOT_DEBT_TO_TOT_EQY', 'BS_TOT_LIAB2', 'BS_TOT_ASSET', 'IS_EPS',\n",
      "       'PX_HIGH', 'PX_LOW', 'PX_CLOSE_1D', 'PX_VOLUME', 'TURNOVER', 'ticker',\n",
      "       'DVD_SH_12M'],\n",
      "      dtype='object')\n",
      "Applying label transformations globally to the dataset (before partitioning).\n",
      " Applying BinaryLabelTransform with params {'label_duration': 20, 'quantile': 0.75} (globally)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LO79RS\\topquartile\\topquartile\\modules\\datamodule\\transforms\\label.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.ihsg.index = pd.to_datetime(self.ihsg.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: DataFrame is not MultiIndexed by 'DateIndex'. \n",
      "Data processing complete.\n",
      "Partitioning data using PurgedTimeSeriesPartition for 5 splits across 85 tickers.\n",
      "Fold 0: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 1: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 2: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 3: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 4: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Partitioning complete. Generated 5 CV folds.\n"
     ]
    }
   ],
   "source": [
    "folds = dataloader.get_cv_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5aed30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not yet processed. Processing now...\n",
      "Reading data from: C:\\Users\\LO79RS\\topquartile\\topquartile\\data\\covariates_may2025v2.csv\n",
      "Found 134 raw ticker names.\n",
      " Applying TechnicalCovariateTransform with params {'sma': [20, 30], 'ema': [20, 30], 'momentum_change': True, 'volatility': [20, 30]}\n",
      "THIS IS COLUMNS Index(['TOTAL_EQUITY', 'BOOK_VAL_PER_SH', 'REVENUE_PER_SH', 'RETURN_COM_EQY',\n",
      "       'CUR_MKT_CAP', 'PX_LAST', 'TOT_DEBT_TO_TOT_ASSET',\n",
      "       'TOT_DEBT_TO_TOT_EQY', 'BS_TOT_LIAB2', 'BS_TOT_ASSET', 'IS_EPS',\n",
      "       'PX_HIGH', 'PX_LOW', 'PX_CLOSE_1D', 'PX_VOLUME', 'TURNOVER', 'ticker',\n",
      "       'DVD_SH_12M'],\n",
      "      dtype='object')\n",
      "Applying label transformations globally to the dataset (before partitioning).\n",
      " Applying BinaryLabelTransform with params {'label_duration': 20, 'quantile': 0.75} (globally)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LO79RS\\topquartile\\topquartile\\modules\\datamodule\\transforms\\label.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.ihsg.index = pd.to_datetime(self.ihsg.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: DataFrame is not MultiIndexed by 'DateIndex'. \n",
      "Data processing complete.\n",
      "Partitioning data using PurgedTimeSeriesPartition for 5 splits across 85 tickers.\n",
      "Fold 0: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 1: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 2: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 3: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Fold 4: Train shape (42840, 29), Test shape (5100, 29)\n",
      "Partitioning complete. Generated 5 CV folds.\n",
      "['TOTAL_EQUITY', 'BOOK_VAL_PER_SH', 'REVENUE_PER_SH', 'RETURN_COM_EQY', 'CUR_MKT_CAP', 'PX_LAST', 'TOT_DEBT_TO_TOT_ASSET', 'TOT_DEBT_TO_TOT_EQY', 'BS_TOT_LIAB2', 'BS_TOT_ASSET', 'IS_EPS', 'PX_HIGH', 'PX_LOW', 'PX_CLOSE_1D', 'PX_VOLUME', 'TURNOVER', 'ticker', 'sma_20', 'sma_30', 'ema_20', 'ema_30', 'volatility_20', 'volatility_30', 'roc_126', 'momentum_change', 'eq_returns_20', 'index_returns_20', 'excess_returns_20', 'label']\n"
     ]
    }
   ],
   "source": [
    "folds = dataloader.get_cv_folds()\n",
    "train_df, test_df = folds[0]\n",
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5919, 28)\n",
      "Test shape: (240, 28)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = folds[0]\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "X_train = train_df.drop(columns=[\"label\"])\n",
    "X_test = test_df.drop(columns=[\"label\"])\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7036b610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64     26\n",
       "object       1\n",
       "category     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebcbc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TOTAL_EQUITY'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbba803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"TOTAL_EQUITY\"])\n",
    "X_test = X_test.drop(columns=[\"TOTAL_EQUITY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b3c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64     26\n",
       "category     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d524b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include=[\"category\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88dd20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"ticker\"])\n",
    "X_test = X_test.drop(columns=[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b66f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f\"Model accuracy on test set: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5b009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = [\"label\", \"EXCESS_RETURN\", \"INDEX_RETURN\", \"30d_stock_return\", \"ticker\"]\n",
    "X_train = train_df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "X_test = test_df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce9dd660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model accuracy on test set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "\n",
    "print(f\" Model accuracy on test set: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1afbaed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def train_one_fold(fold_id: int) -> float:\n",
    "    train_df, test_df = folds[fold_id]\n",
    "    train_df = train_df.dropna(subset=[\"label\"])\n",
    "    test_df = test_df.dropna(subset=[\"label\"])\n",
    "    y_train = train_df[\"label\"]\n",
    "    y_test = test_df[\"label\"]\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"label\"])\n",
    "    X_test = test_df.drop(columns=[\"label\"])\n",
    "    X_train = X_train.drop(columns=[\"ticker\"], errors=\"ignore\")\n",
    "    X_test = X_test.drop(columns=[\"ticker\"], errors=\"ignore\")\n",
    "    X_train = X_train.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "    X_test = X_test.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "    model = RandomForestQuantileRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features=0.8,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    y_pred = model.predict(X_test.values, quantiles=[0.5])\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "550818ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 0\n",
      "Fold 0 RMSE: 0.0000\n",
      "Training on fold 1\n",
      "Fold 1 RMSE: 0.0000\n",
      "Training on fold 2\n",
      "Fold 2 RMSE: 0.0000\n",
      "Training on fold 3\n",
      "Fold 3 RMSE: 0.0000\n",
      "Training on fold 4\n",
      "Fold 4 RMSE: 0.0000\n",
      "\n",
      "Average RMSE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "rmses = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    print(f\"Training on fold {fold_id}\")\n",
    "    rmse = train_one_fold(fold_id)\n",
    "    print(f\"Fold {fold_id} RMSE: {rmse:.4f}\")\n",
    "    rmses.append(rmse)\n",
    "\n",
    "print(f\"\\nAverage RMSE: {np.mean(rmses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46008b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
