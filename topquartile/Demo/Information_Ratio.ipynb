{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection._split import _BaseKFold"
      ],
      "metadata": {
        "id": "LpmJp0alNsAk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hZlh6hhrMh4X"
      },
      "outputs": [],
      "source": [
        "def information_ratio(strategy_returns, benchmark_returns):\n",
        "    \"\"\"\n",
        "    Compute the Information Ratio (IR) of a strategy.\n",
        "\n",
        "    IR = mean(active return) / std(active return)\n",
        "    Active return = strategy return - benchmark return\n",
        "\n",
        "    Parameters:\n",
        "        strategy_returns (array-like): Returns of your strategy.\n",
        "        benchmark_returns (array-like): Returns of benchmark (e.g., market).\n",
        "\n",
        "    Returns:\n",
        "        float: Information ratio. Returns 0 if tracking error is 0.\n",
        "    \"\"\"\n",
        "    # Convert to numpy arrays\n",
        "    strategy_returns = np.asarray(strategy_returns)\n",
        "    benchmark_returns = np.asarray(benchmark_returns)\n",
        "\n",
        "    # Validation\n",
        "    if strategy_returns.shape != benchmark_returns.shape:\n",
        "        raise ValueError(\"Strategy and benchmark returns must have the same shape.\")\n",
        "\n",
        "    # Handle NaNs\n",
        "    mask = ~np.isnan(strategy_returns) & ~np.isnan(benchmark_returns)\n",
        "    if np.sum(mask) == 0:\n",
        "        return 0\n",
        "\n",
        "    active_returns = strategy_returns[mask] - benchmark_returns[mask]\n",
        "    tracking_error = np.std(active_returns)\n",
        "\n",
        "    return np.mean(active_returns) / tracking_error if tracking_error > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, df, label_col='MarketRegimeLabel', return_col='returns', drop_cols=None):\n",
        "    \"\"\"\n",
        "    Optuna objective function using Information Ratio as the evaluation metric.\n",
        "\n",
        "    Parameters:\n",
        "        trial: Optuna trial object\n",
        "        df (pd.DataFrame): DataFrame containing features, labels, and returns\n",
        "        label_col (str): Column name for target variable\n",
        "        return_col (str): Column name for realized returns\n",
        "        drop_cols (list): List of columns to drop from features (e.g., ['Date', 'Asset', ...])\n",
        "\n",
        "    Returns:\n",
        "        float: Average information ratio across cross-validation folds\n",
        "    \"\"\"\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    # Suggest hyperparameters\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Prepare data\n",
        "    if drop_cols is None:\n",
        "        drop_cols = []\n",
        "\n",
        "    X = df.drop(columns=drop_cols + [label_col, return_col])\n",
        "    y = df[label_col].values\n",
        "    returns = df[return_col].values\n",
        "\n",
        "    # Time-series aware CV\n",
        "    pgts = PurgedGroupTimeSeriesSplit(n_splits=5, group_gap=5)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, test_idx in pgts.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "        returns_test = returns[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        # Generate strategy returns based on predictions\n",
        "        strat_returns = []\n",
        "        for p, r in zip(preds, returns_test):\n",
        "            if p == 1: strat_returns.append(r)       # long\n",
        "            elif p == 0: strat_returns.append(-r)     # short\n",
        "            else: strat_returns.append(0)             # neutral\n",
        "\n",
        "        strat_returns = np.array(strat_returns)\n",
        "        benchmark_returns = np.zeros_like(strat_returns)  # assuming cash as benchmark\n",
        "\n",
        "        score = information_ratio(strat_returns, benchmark_returns)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "BwGwpOOaMsvo"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}